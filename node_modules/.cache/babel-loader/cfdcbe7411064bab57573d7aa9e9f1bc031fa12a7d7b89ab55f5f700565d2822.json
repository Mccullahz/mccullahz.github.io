{"ast":null,"code":"export const contentRegistry=[{/*\tThis setup is pretty straight forward, but\n * \ttype: is used to differentiate between templates and projects, this changes what page the content is displayed on\n *  \tslug: is used to create the URL for the page, so it should be unique and descriptive for each item\n *  \ttitle: is the main title of the content item, displayed prominently on the card and the page\n *  \tsubtitle: is the secondary heading, only displayed on the card\n *  \ttechnologies: is an array of strings representing the technologies used, displayed on the card\n *  \tlinks: is an object containing optional links, shown on the card only\n *  \tcontent: is the main content of the item, displayed on the page, rendered as markdown, use \\`\\`\\`markdown to showcase markdown without formatting\n *\n * */type:\"template\",slug:\"sow-template\",title:\"Statement of Work - SOW Template\",subtitle:\"A straightforward template to organize solo dev projects.\",technologies:[\"Markdown\",\"PDF Download\"],links:{github:\"None here :)\"},content:\"\\n## Overview\\n\\nThis is a simple template for a **Statement of Work (SOW)** document.\\n\\n## Features\\n- Clear sections for scope, objectives, and deliverables\\n- Lightweight Markdown formatting\\n- Ideal for solo developers and small teams\\n\\n#### Markdown Format Doc\\n\\n```markdown\\n# Statement of Work (SOW)\\n\\n## 1. Project Title\\n**[Title]**  \\n_Description_\\n\\n---\\n\\n## 2. Project Overview\\n\\nA brief description of the project, its purpose, and its significance.\\n---\\n\\n## 3. Objectives\\nClear, measurable objectives this project aims to achieve.\\n\\n\\n---\\n\\n## 4. Scope of Work\\n\\n### 4.1 In Scope\\nSpecific features, deliverables, and services to be included:\\n\\n\\n### 4.2 Out of Scope\\nClarify what will not be covered:\\n\\n\\n---\\n\\n## 5. Deliverables\\n\\n| Deliverable               | Description                                |\\n|---------------------------|--------------------------------------------|\\n|                           |                                            |\\n\\n---\\n\\n## 6. Timeline & Milestones\\n\\n3xbackticksmermaid\\ngantt\\ntitle Project Timeline\\ndateFormat  YYYY-MM-DD\\nsection Planning\\n    Gantt timeline data      :a1, 2023-10-01, 2w\\n3xbackticks\\n\\n---\\n\\n## 7. Assumptions\\n\\n\\n---\\n\\n## 8. Constraints\\n\\n\\n---\\n\\n## 9. Acceptance Criteria\\nThis project will be considered complete when:\\n```\\n    \"},{type:\"project\",slug:\"job-scraper-cli\",title:\"Job Scraper CLI\",subtitle:\"Scrapes business websites near a ZIP code for job pages.\",technologies:[\"Go\",\"Bubbletea\",\"Lipgloss\"],links:{github:\"PRIVATEhttps://github.com/Mccullahz/cli-scraper\"},content:\"\\n# Table of contents\\n1. [Overview](#overview)\\n2. [Structure](#structure)\\n3. [Terminal Interface](#TUI)\\n4. [Scraping](#scraping)\\n\\t1. [Concurrency](#concurrency)\\n\\n\\n## Overview\\nThis CLI Job Scraper is a Go powered TUI application that finds nearby business websites and searches them for career or job listing pages. The goal is to automate localized job hunting by surfacing hiring pages often buried in small business websites. \\n\\nBy searching only these local businesses, applicants can find job opportunities that may not be listed on larger job boards, reducing resume traffic and potentially aiding in landing a desired position.\\n\\n## Structure\\nThis project is structured similar to a standard Go application, with the main logic in the 'cmd' directory. This main function only acts as the entry point of the project. The rest of the Go packages are placed inside the internal directory, and further split into packages to modulate each function. \\n\\nTUI interface is inside the ui package, the 'scraper' that handles HTTP requests is located inside web, and so fourth.\\n\\n## Terminal Interface\\nThe TUI is built using the Bubbletea library, which provides a simple and effective way to create terminal user interfaces in Go, and styled with the Lipgloss addition to Bubbletea. The interface allows users to input a ZIP code, select a radius for scraping, and view the results in a structured format. The UI is designed to be intuitive and responsive, and will eventually be able to provide real time feedback as the scraper processes each website.\\n\\n\\n## Scraping\\nThe scraping functionality is implemented using Go's 'net/http' package to make HTTP requests and 'goquery' for parsing HTML. The scraper first locates all pages attached to a zipcode via our Geo Package, then parses every page within the radius. We are then parsing the HTML to find links that match common job listing patterns, such as \\\"careers\\\", \\\"jobs\\\", or \\\"employment\\\".\\n### Concurrency\\nThe scraper uses Go's goroutines to handle multiple HTTP requests concurrently, significantly speeding up the scraping process. Each request is handled in a separate goroutine, allowing the application to scrape multiple websites simultaneously without blocking the main thread.\\n\\n\"},{type:\"project\",slug:\"flacer\",title:\"Flacer\",subtitle:\"An in development cross-platform high resolution audio player.\",technologies:[\"Go\",\"Wails\",\"TypeScript\"],links:{github:\"https://www.github.com/Mccullahz/flacer\"},content:\"\\nFlacer is a cross platform audio player designed for high resolution audio playback. It aims to provide a seamless listening experience with support for various audio formats and a user friendly interface. The project is built using Go for the backend and Wails for the frontend, leveraging TypeScript for enhanced development efficiency.\\n\\t\\t\"}];export function getContentBySlug(slug){return contentRegistry.find(item=>item.slug===slug);}","map":{"version":3,"names":["contentRegistry","type","slug","title","subtitle","technologies","links","github","content","getContentBySlug","find","item"],"sources":["/home/zyguythearchguy/code/mccullahz.github.io/src/data/ContentReg.tsx"],"sourcesContent":["export type ContentItem = {\n  slug: string;\n  title: string;\n  subtitle?: string;\n  technologies?: string[];\n  links?: {\n    github?: string;\n    demo?: string;\n    download?: string;\n  };\n  content: string;\n  type: \"template\" | \"project\";\n};\n\nexport const contentRegistry: ContentItem[] = [\n  {\n/*\tThis setup is pretty straight forward, but\n * \ttype: is used to differentiate between templates and projects, this changes what page the content is displayed on\n *  \tslug: is used to create the URL for the page, so it should be unique and descriptive for each item\n *  \ttitle: is the main title of the content item, displayed prominently on the card and the page\n *  \tsubtitle: is the secondary heading, only displayed on the card\n *  \ttechnologies: is an array of strings representing the technologies used, displayed on the card\n *  \tlinks: is an object containing optional links, shown on the card only\n *  \tcontent: is the main content of the item, displayed on the page, rendered as markdown, use \\`\\`\\`markdown to showcase markdown without formatting\n *\n * */\n\n    type: \"template\",\n    slug: \"sow-template\",\n    title: \"Statement of Work - SOW Template\",\n    subtitle: \"A straightforward template to organize solo dev projects.\",\n    technologies: [\"Markdown\", \"PDF Download\"],\n    links: {\n      github: \"None here :)\",\n    },\n    content: `\n## Overview\n\nThis is a simple template for a **Statement of Work (SOW)** document.\n\n## Features\n- Clear sections for scope, objectives, and deliverables\n- Lightweight Markdown formatting\n- Ideal for solo developers and small teams\n\n#### Markdown Format Doc\n\n\\`\\`\\`markdown\n# Statement of Work (SOW)\n\n## 1. Project Title\n**[Title]**  \n_Description_\n\n---\n\n## 2. Project Overview\n\nA brief description of the project, its purpose, and its significance.\n---\n\n## 3. Objectives\nClear, measurable objectives this project aims to achieve.\n\n\n---\n\n## 4. Scope of Work\n\n### 4.1 In Scope\nSpecific features, deliverables, and services to be included:\n\n\n### 4.2 Out of Scope\nClarify what will not be covered:\n\n\n---\n\n## 5. Deliverables\n\n| Deliverable               | Description                                |\n|---------------------------|--------------------------------------------|\n|                           |                                            |\n\n---\n\n## 6. Timeline & Milestones\n\n3xbackticksmermaid\ngantt\ntitle Project Timeline\ndateFormat  YYYY-MM-DD\nsection Planning\n    Gantt timeline data      :a1, 2023-10-01, 2w\n3xbackticks\n\n---\n\n## 7. Assumptions\n\n\n---\n\n## 8. Constraints\n\n\n---\n\n## 9. Acceptance Criteria\nThis project will be considered complete when:\n\\`\\`\\`\n    `,\n  },\n\n\n  {\n    type: \"project\",\n    slug: \"job-scraper-cli\",\n    title: \"Job Scraper CLI\",\n    subtitle: \"Scrapes business websites near a ZIP code for job pages.\",\n    technologies: [\"Go\", \"Bubbletea\", \"Lipgloss\"],\n    links: {\n      github: \"PRIVATEhttps://github.com/Mccullahz/cli-scraper\",\n    },\n    content: `\n# Table of contents\n1. [Overview](#overview)\n2. [Structure](#structure)\n3. [Terminal Interface](#TUI)\n4. [Scraping](#scraping)\n\t1. [Concurrency](#concurrency)\n\n\n## Overview\nThis CLI Job Scraper is a Go powered TUI application that finds nearby business websites and searches them for career or job listing pages. The goal is to automate localized job hunting by surfacing hiring pages often buried in small business websites. \n\nBy searching only these local businesses, applicants can find job opportunities that may not be listed on larger job boards, reducing resume traffic and potentially aiding in landing a desired position.\n\n## Structure\nThis project is structured similar to a standard Go application, with the main logic in the 'cmd' directory. This main function only acts as the entry point of the project. The rest of the Go packages are placed inside the internal directory, and further split into packages to modulate each function. \n\nTUI interface is inside the ui package, the 'scraper' that handles HTTP requests is located inside web, and so fourth.\n\n## Terminal Interface\nThe TUI is built using the Bubbletea library, which provides a simple and effective way to create terminal user interfaces in Go, and styled with the Lipgloss addition to Bubbletea. The interface allows users to input a ZIP code, select a radius for scraping, and view the results in a structured format. The UI is designed to be intuitive and responsive, and will eventually be able to provide real time feedback as the scraper processes each website.\n\n\n## Scraping\nThe scraping functionality is implemented using Go's 'net/http' package to make HTTP requests and 'goquery' for parsing HTML. The scraper first locates all pages attached to a zipcode via our Geo Package, then parses every page within the radius. We are then parsing the HTML to find links that match common job listing patterns, such as \"careers\", \"jobs\", or \"employment\".\n### Concurrency\nThe scraper uses Go's goroutines to handle multiple HTTP requests concurrently, significantly speeding up the scraping process. Each request is handled in a separate goroutine, allowing the application to scrape multiple websites simultaneously without blocking the main thread.\n\n`,\n  },\n\n  {\n    type: \"project\",\n    slug: \"flacer\",\n    title: \"Flacer\",\n    subtitle: \"An in development cross-platform high resolution audio player.\",\n    technologies: [\"Go\", \"Wails\", \"TypeScript\"],\n    links: {\n      github: \"https://www.github.com/Mccullahz/flacer\",\n    },\n    content: `\nFlacer is a cross platform audio player designed for high resolution audio playback. It aims to provide a seamless listening experience with support for various audio formats and a user friendly interface. The project is built using Go for the backend and Wails for the frontend, leveraging TypeScript for enhanced development efficiency.\n\t\t`,\n  },\n\n\n];\n\nexport function getContentBySlug(slug: string): ContentItem | undefined {\n  return contentRegistry.find((item) => item.slug === slug);\n}\n\n"],"mappings":"AAcA,MAAO,MAAM,CAAAA,eAA8B,CAAG,CAC5C,CACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAEIC,IAAI,CAAE,UAAU,CAChBC,IAAI,CAAE,cAAc,CACpBC,KAAK,CAAE,kCAAkC,CACzCC,QAAQ,CAAE,2DAA2D,CACrEC,YAAY,CAAE,CAAC,UAAU,CAAE,cAAc,CAAC,CAC1CC,KAAK,CAAE,CACLC,MAAM,CAAE,cACV,CAAC,CACDC,OAAO,i0CA8ET,CAAC,CAGD,CACEP,IAAI,CAAE,SAAS,CACfC,IAAI,CAAE,iBAAiB,CACvBC,KAAK,CAAE,iBAAiB,CACxBC,QAAQ,CAAE,0DAA0D,CACpEC,YAAY,CAAE,CAAC,IAAI,CAAE,WAAW,CAAE,UAAU,CAAC,CAC7CC,KAAK,CAAE,CACLC,MAAM,CAAE,iDACV,CAAC,CACDC,OAAO,2tEA6BT,CAAC,CAED,CACEP,IAAI,CAAE,SAAS,CACfC,IAAI,CAAE,QAAQ,CACdC,KAAK,CAAE,QAAQ,CACfC,QAAQ,CAAE,gEAAgE,CAC1EC,YAAY,CAAE,CAAC,IAAI,CAAE,OAAO,CAAE,YAAY,CAAC,CAC3CC,KAAK,CAAE,CACLC,MAAM,CAAE,yCACV,CAAC,CACDC,OAAO,6VAGT,CAAC,CAGF,CAED,MAAO,SAAS,CAAAC,gBAAgBA,CAACP,IAAY,CAA2B,CACtE,MAAO,CAAAF,eAAe,CAACU,IAAI,CAAEC,IAAI,EAAKA,IAAI,CAACT,IAAI,GAAKA,IAAI,CAAC,CAC3D","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}